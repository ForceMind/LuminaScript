from fastapi import FastAPI, Depends, HTTPException, BackgroundTasks, status
from fastapi.security import OAuth2PasswordRequestForm
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from sqlalchemy.orm import selectinload
from typing import List
from pydantic import BaseModel 
import json

from database import init_db, get_db
import models
import schemas
import auth
from services import llm  # Import LLM Service
import logging
import sys

# Configure Logging
logging.basicConfig(
    level=logging.INFO, # Changed to INFO to avoid too much noise but capture essential flows
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("lumina_backend")

# Initialize App
app = FastAPI(title="LuminaScript API", version="0.1.0")

import asyncio

@app.on_event("startup")
async def on_startup():
    logger.info("æœåŠ¡å™¨æ­£åœ¨å¯åŠ¨...")
    await init_db()
    logger.info("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼ŒæœåŠ¡å‡†å¤‡å°±ç»ªã€‚")

@app.get("/")
async def root():
    logger.info("æ”¶åˆ°æ ¹è·¯å¾„è¯·æ±‚")
    return {"message": "æ¬¢è¿ä½¿ç”¨å¦™ç¬”æµå…‰ (LuminaScript) API"}

# --- Auth Routes ---

@app.post("/token", response_model=schemas.Token)
async def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends(), db: AsyncSession = Depends(get_db)):
    logger.info(f"æ”¶åˆ°ç™»å½•è¯·æ±‚: ç”¨æˆ·å={form_data.username}")
    # 1. Fetch user
    result = await db.execute(select(models.User).where(models.User.username == form_data.username))
    user = result.scalars().first()
    
    # 2. Verify
    if not user:
        logger.warning(f"ç™»å½•å¤±è´¥: ç”¨æˆ· {form_data.username} ä¸å­˜åœ¨")
    elif not auth.verify_password(form_data.password, user.hashed_password):
        logger.warning(f"ç™»å½•å¤±è´¥: ç”¨æˆ· {form_data.username} å¯†ç é”™è¯¯")
        
    if not user or not auth.verify_password(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    logger.info(f"ç”¨æˆ· {form_data.username} ç™»å½•æˆåŠŸ")
    # 3. Create Token
    access_token = auth.create_access_token(data={"sub": user.username})
    return {"access_token": access_token, "token_type": "bearer"}

@app.post("/auth/register", response_model=schemas.UserResponse)
async def register(user: schemas.UserCreate, db: AsyncSession = Depends(get_db)):
    # Check existing
    result = await db.execute(select(models.User).where(models.User.username == user.username))
    if result.scalars().first():
        raise HTTPException(status_code=400, detail="Username already registered")
    
    # Create
    hashed_pw = auth.get_password_hash(user.password)
    new_user = models.User(username=user.username, hashed_password=hashed_pw)
    db.add(new_user)
    await db.commit()
    await db.refresh(new_user)
    return new_user

@app.get("/users/me", response_model=schemas.UserResponse)
async def read_users_me(current_user: models.User = Depends(auth.get_current_user)):
    return current_user

# --- Project Management ---

@app.post("/projects/", response_model=schemas.ProjectResponse)
async def create_project(
    project: schemas.ProjectCreate, 
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    logger.info(f"ç”¨æˆ· {current_user.username} æ­£åœ¨åˆ›å»ºæ–°é¡¹ç›®ï¼ŒLogline: {project.logline[:50]}...")
    # 1. First step: Create the project record based on logline
    # Real implementation would call LLM here to analyze logline first, 
    # but for now we just save it.
    new_project = models.Project(
        title=project.title,
        logline=project.logline,
        project_type=project.project_type,
        owner_id=current_user.id
    )
    db.add(new_project)
    await db.commit()
    await db.refresh(new_project)
    
    logger.info(f"é¡¹ç›®åˆ›å»ºæˆåŠŸ ID: {new_project.id}")

    # Reload to ensure relationships (scenes) are loaded for Pydantic
    result = await db.execute(
        select(models.Project)
        .where(models.Project.id == new_project.id)
        .options(selectinload(models.Project.scenes))
    )
    return result.scalars().first()

@app.get("/projects/", response_model=List[schemas.ProjectResponse])
async def list_projects(
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    result = await db.execute(
        select(models.Project)
        .where(models.Project.owner_id == current_user.id)
        .options(selectinload(models.Project.scenes))
    )
    return result.scalars().all()


@app.delete("/projects/{project_id}")
async def delete_project(
    project_id: int, 
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    project = await db.get(models.Project, project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=404, detail="Project not found")
    
    # Mark as failed/deleted to stop background tasks
    project.status = models.ProcessingStatus.FAILED 
    await db.delete(project)
    await db.commit()
    return {"status": "success"}

@app.patch("/projects/{project_id}", response_model=schemas.ProjectResponse)
async def update_project(
    project_id: int,
    project_update: schemas.ProjectUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    # Use select with options to eager load scenes to avoid MissingGreenlet error in response validation
    result = await db.execute(
        select(models.Project)
        .where(models.Project.id == project_id)
        .options(selectinload(models.Project.scenes))
    )
    project = result.scalars().first()

    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=404, detail="Project not found")
    
    if project_update.project_type:
        project.project_type = project_update.project_type
    
    await db.commit()
    await db.refresh(project)
    return project

class InteractionRequest(BaseModel):
    answer: str
    context_key: str

@app.post("/projects/{project_id}/interact")
async def submit_interaction(
    project_id: int,
    interaction: InteractionRequest,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    logger.info(f"æ”¶åˆ°é¡¹ç›® {project_id} çš„äº¤äº’å›ç­”: Key={interaction.context_key}, Answer={interaction.answer}")
    
    result = await db.execute(
        select(models.Project).where(models.Project.id == project_id)
    )
    project = result.scalars().first()
    
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=404, detail="Project not found")

    # Update context
    # Note: sqlalchemy JSON field needs reassignment to trigger update
    current_context = dict(project.global_context) if project.global_context else {}
    current_context[interaction.context_key] = interaction.answer
    project.global_context = current_context

    # Ensure project_type is synced if that was the key (legacy support)
    if interaction.context_key == 'project_type':
        project.project_type = interaction.answer
    
    # Handle Title Update specifically
    if interaction.context_key == 'title':
        project.title = interaction.answer
        
    # Clear the cache because state has changed
    project.next_step_cache = None

    await db.commit()
    logger.info(f"é¡¹ç›® {project_id} ä¸Šä¸‹æ–‡å·²æ›´æ–°ï¼Œç¼“å­˜å·²æ¸…é™¤")
    return {"status": "updated", "context": project.global_context}


@app.post("/projects/{project_id}/analyze")
async def analyze_logline(
    project_id: int, 
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    """
    Phase 1: Deep Analysis & Setup.
    Iteratively helps the user build the 'Project Bible' by asking questions.
    """
    project = await db.get(models.Project, project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=404, detail="Project not found")

    # Check Cache First (For resuming sessions)
    if project.next_step_cache:
        logger.info(f"é¡¹ç›® {project_id} å‘½ä¸­ç¼“å­˜ï¼Œç›´æ¥è¿”å›ä¹‹å‰çš„æé—®ã€‚")
        return project.next_step_cache

    logger.info(f"æ­£åœ¨åˆ†æé¡¹ç›® {project_id} çš„è¿›åº¦çŠ¶å†µ...")

    context = project.global_context or {}
    
    # --- Definition of the 10-Step Setup Flow ---
    REQUIRED_STEPS = [
        {"key": "project_type", "question": "æ‚¨æƒ³åˆ›ä½œå“ªç§ç±»å‹çš„å‰§æœ¬ï¼Ÿ", "default_options": [
             {"label": "ğŸ¥ ç”µå½±å‰§æœ¬ (Movie)", "value": "movie"},
             {"label": "ğŸ“º ç”µè§†å‰§ (TV Series)", "value": "tv"},
             {"label": "ğŸ“± ç°ä»£çŸ­å‰§ (Short Drama)", "value": "short"}
        ]},
        {"key": "tone", "question": "è¿™éƒ¨ä½œå“çš„åŸºè°ƒæ˜¯ä»€ä¹ˆï¼Ÿ"},
        {"key": "time_period", "question": "æ•…äº‹å‘ç”Ÿåœ¨ä»€ä¹ˆæ—¶ä»£èƒŒæ™¯ï¼Ÿ"},
        {"key": "title", "question": "ä¸ç®¡æ˜¯æš‚å®šè¿˜æ˜¯æ­£å¼ï¼Œç»™è¿™ä¸ªæ•…äº‹èµ·ä¸ªåå­—å§ï¼Ÿ"},
        {"key": "protagonist_core", "question": "ä¸»è§’çš„æ ¸å¿ƒç‰¹å¾æˆ–æœ€å¤§æ¬²æœ›æ˜¯ä»€ä¹ˆï¼Ÿ"},
        {"key": "antagonist_obstacle", "question": "ä¸»è§’é¢ä¸´çš„æœ€å¤§é˜»ç¢æˆ–åæ´¾æ˜¯è°ï¼Ÿ"},
        {"key": "central_conflict", "question": "æ•…äº‹çš„æ ¸å¿ƒå†²çªæˆ–ä¸¤éš¾å›°å¢ƒæ˜¯ä»€ä¹ˆï¼Ÿ"},
        {"key": "theme", "question": "æ‚¨æƒ³é€šè¿‡è¿™ä¸ªæ•…äº‹æ¢è®¨ä»€ä¹ˆä¸»é¢˜ï¼Ÿ"},
        {"key": "visual_style", "question": "è§†è§‰é£æ ¼åå‘äºä»€ä¹ˆï¼Ÿï¼ˆå¦‚ï¼šèµ›åšæœ‹å…‹ã€å†™å®ã€é»‘ç™½è¯ºå°”ç­‰ï¼‰"},
        {"key": "target_audience", "question": "æ‚¨é¢„æƒ³çš„ç›®æ ‡è§‚ä¼—æ˜¯è°ï¼Ÿ"}
    ]

    # 1. Check which steps are missing
    # Important: 'project_type' is stored in column, others in global_context
    normalized_context = context.copy()
    if project.project_type and project.project_type != "pending":
        normalized_context['project_type'] = project.project_type

    next_step = None
    for step in REQUIRED_STEPS:
        if step["key"] not in normalized_context:
            next_step = step
            break
            
    # 2. If all steps completed -> Proceed to Outline Generation
    if not next_step:
        logger.info(f"é¡¹ç›® {project_id} æ‰€æœ‰åŸºç¡€è®¾å®šæ­¥éª¤å·²å®Œæˆï¼Œå‡†å¤‡ç”Ÿæˆå¤§çº²ã€‚")
        # Check if Outline exists, if not, generate it
        # return {"type": "complete", "message": "Bible complete. Ready for Outline."}
        # For now, let's trigger scene generation or "outline confirmation"
        return {"type": "completed", "message": "åŸºç¡€è®¾å®šå·²å®Œæˆï¼å‡†å¤‡ç”Ÿæˆå¤§çº²..."}

    logger.info(f"é¡¹ç›® {project_id} ä¸‹ä¸€æ­¥éª¤: {next_step['key']}")

    # 3. Handle specific logic for the next step
    # 3.1 Hardcoded options for Type
    if next_step["key"] == "project_type":
        return {
            "type": "interaction_required",
            "payload": {
                "field": "project_type",
                "question": next_step["question"],
                "options": next_step["default_options"]
            }
        }

    # 3.2 For other steps, use LLM to generate context-aware options
    # We pass the logline + current context to LLM
    prompt_context = f"Logline: {project.logline}\nCurrent Settings: {json.dumps(normalized_context, ensure_ascii=False)}"
    
    logger.info(f"æ­£åœ¨è°ƒç”¨ LLM ä¸ºæ­¥éª¤ {next_step['key']} ç”Ÿæˆé€‰é¡¹...")
    
    # 3.2 For other steps, use LLM to generate context-aware options
    question_data, usage = await llm.generate_interaction_options(
        step_key=next_step["key"],
        base_question=next_step["question"],
        context_str=prompt_context
    )
    
    # Update Token Usage
    project.total_tokens += usage
    
    # Construction Response
    response_payload = {
        "type": "interaction_required",
        "payload": {
            "field": next_step["key"],
            "question": question_data.get("question", next_step["question"]), 
            "options": question_data.get("options", [])
        }
    }
    
    # Cache the result to DB so next fetch is instant
    project.next_step_cache = response_payload
    await db.commit()

    return response_payload

@app.post("/projects/{project_id}/generate_scenes")
async def generate_scenes(
    project_id: int, 
    selected_option: str = None, 
    background_tasks: BackgroundTasks = BackgroundTasks(),
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    """
    Phase 1.5: User selected an option, now generate outline.
    Phase 2: Add background task for generation.
    """
    logger.info(f"æ”¶åˆ°ç”Ÿæˆåˆ†åœºå¤§çº²è¯·æ±‚ï¼Œé¡¹ç›®ID: {project_id}")
    # 1. Update project genre/style based on selected_option
    project = await db.get(models.Project, project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=404, detail="Project not found")
    
    # Use selected_option if string generic, or fallback to stored context values
    style_context = selected_option
    if not style_context:
        # Construct summary from context
        c = project.global_context or {}
        style_context = f"Genre: {project.project_type}, Tone: {c.get('tone')}, Style: {c.get('visual_style')}"

    project.genre = style_context
    await db.commit()

    logger.info(f"æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆåˆ†åœºå¤§çº²... (Style: {style_context})")
    # 2. Real: Generate Scene Outline using LLM
    scenes_data, usage = await llm.generate_outline(project.logline, style_context)
    project.total_tokens += usage
    
    if not scenes_data:
        logger.error("åˆ†åœºå¤§çº²ç”Ÿæˆå¤±è´¥æˆ–ä¸ºç©º")
        # Fallback
        scenes_data = [{"index": 1, "outline": "Start: Intro Protagonist"}]
    else:
        logger.info(f"æˆåŠŸç”Ÿæˆ {len(scenes_data)} ä¸ªåˆ†åœº")

    # Clear existing scenes if any (cleanup for retry)
    # Note: For basic version, we just append. Advanced: delete old.
    
    for scene_item in scenes_data:
        new_scene = models.Scene(
            project_id=project.id,
            scene_index=scene_item.get("index", 1),
            outline=scene_item.get("outline", "Unknown Scene"),
            status=models.ProcessingStatus.PENDING
        )
        db.add(new_scene)
    
    project.status = models.ProcessingStatus.GENERATING
    await db.commit()
    
    # 3. Trigger Background Loop (Concept)
    logger.info(f"å¯åŠ¨åå°ä»»åŠ¡ç”Ÿæˆå…·ä½“çš„å‰§æœ¬å†…å®¹...")
    background_tasks.add_task(run_generation_loop, project.id)
    
    return {"status": "Scene generation started", "project_id": project_id}

# --- Background Task (The Engine) ---

async def run_generation_loop(project_id: int):
    """
    The Core Loop: Iterates scenes and generates content with Rolling Summary.
    """
    logger.info(f"[åå°ä»»åŠ¡] å¼€å§‹ä¸ºé¡¹ç›® {project_id} ç”Ÿæˆå‰§æœ¬å†…å®¹...")
    
    # Create a new session for the background task
    async with database.SessionLocal() as db:
        # Load Project Info
        project = await db.get(models.Project, project_id)
        if not project: 
            logger.error(f"[åå°ä»»åŠ¡] é¡¹ç›® {project_id} æœªæ‰¾åˆ°ï¼Œä»»åŠ¡ä¸­æ­¢")
            return

        # Load scenes
        result = await db.execute(
            select(models.Scene)
            .where(models.Scene.project_id == project_id)
            .order_by(models.Scene.scene_index)
        )
        scenes = result.scalars().all()
        
        cumulative_context = ""

        for scene in scenes:
            # Re-Check Status (User might have deleted/paused)
            await db.refresh(project)
            if project.status == models.ProcessingStatus.FAILED: # Treat as stop signal
                logger.info("[åå°ä»»åŠ¡] æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œä»»åŠ¡ä¸­æ­¢")
                break

            if scene.status == models.ProcessingStatus.COMPLETED:
                continue # Skip already generated

            # 1. Mark as Generating
            logger.info(f"[åå°ä»»åŠ¡] æ­£åœ¨ç”Ÿæˆç¬¬ {scene.scene_index} åœº: {scene.outline[:30]}...")
            scene.status = models.ProcessingStatus.GENERATING
            await db.commit()
            
            # 2. Call LLM to Write Scene
            generated_content, usage = await llm.write_scene_content(
                logline=project.logline,
                style_guide=project.genre,
                current_scene_outline=scene.outline,
                previous_context=cumulative_context
            )
            
            project.total_tokens += usage

            # 3. Update Content
            if generated_content:
                scene.content = generated_content
                # Simple rolling context for now (first 200 chars to avoid token limit in basic version)
                cumulative_context += f"\n[Scene {scene.scene_index} Summary]: {scene.outline}" 
                logger.info(f"[åå°ä»»åŠ¡] ç¬¬ {scene.scene_index} åœºç”Ÿæˆå®Œæˆ")
            else:
                scene.content = "(AI Generation Failed)"
                logger.error(f"[åå°ä»»åŠ¡] ç¬¬ {scene.scene_index} åœºç”Ÿæˆå†…å®¹ä¸ºç©º")

            scene.status = models.ProcessingStatus.COMPLETED
            await db.commit()
        
        # Mark Project Complete
        project.status = models.ProcessingStatus.COMPLETED
        await db.commit()
        logger.info(f"[åå°ä»»åŠ¡] é¡¹ç›® {project_id} æ‰€æœ‰å‰§æœ¬ç”Ÿæˆä»»åŠ¡å®Œæˆï¼")
            
    print(f"Generation loop finished for Project {project_id}")

import database # Import at end to avoid circular dependency issues in loop if needed
